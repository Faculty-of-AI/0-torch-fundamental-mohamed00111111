{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzDBM_v4iMe7"
      },
      "source": [
        "# 00. PyTorch Fundamentals Exercises\n",
        "\n",
        "### 1. Documentation reading \n",
        "\n",
        "A big part of deep learning (and learning to code in general) is getting familiar with the documentation of a certain framework you're using. We'll be using the PyTorch documentation a lot throughout the rest of this course. So I'd recommend spending 10-minutes reading the following (it's okay if you don't get some things for now, the focus is not yet full understanding, it's awareness):\n",
        "  * The documentation on [`torch.Tensor`](https://pytorch.org/docs/stable/tensors.html#torch-tensor).\n",
        "  * The documentation on [`torch.cuda`](https://pytorch.org/docs/master/notes/cuda.html#cuda-semantics).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bGD0oD8Kizak"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "print(\"PyTorch version:\", torch.version)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "__iXqqz-ioUJ"
      },
      "source": [
        "### 2. Create a random tensor with shape `(7, 7)`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pUq9Dc8i2L7"
      },
      "outputs": [],
      "source": [
        "tensor_2 = torch.rand((7,7))\n",
        "print(\"2) tensor_2 shape:\", tensor_2.shape)\n",
        "print(tensor_2)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-XxvRLfiqkR"
      },
      "source": [
        "### 3. Perform a matrix multiplication on the tensor from 2 with another random tensor with shape `(1, 7)` (hint: you may have to transpose the second tensor)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcLqR0Sbi_vT"
      },
      "outputs": [],
      "source": [
        "tensor_3_b = torch.rand((1,7))\n",
        "tensor_3_b_t = tensor_3_b.T\n",
        "matmul_3 = tensor_2 @ tensor_3_b_t\n",
        "print(\"3) Result shape:\", matmul_3.shape)\n",
        "print(matmul_3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiutdKUFiryU"
      },
      "source": [
        "### 4. Set the random seed to `0` and do 2 & 3 over again.\n",
        "\n",
        "The output should be:\n",
        "```\n",
        "(tensor([[1.8542],\n",
        "         [1.9611],\n",
        "         [2.2884],\n",
        "         [3.0481],\n",
        "         [1.7067],\n",
        "         [2.5290],\n",
        "         [1.7989]]), torch.Size([7, 1]))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D-lOWI_1jRMm"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "tensor_4 = torch.rand((7,7))\n",
        "tensor_4_b = torch.rand((1,7))\n",
        "tensor_4_b_t = tensor_4_b.T\n",
        "matmul_4 = tensor_4 @ tensor_4_b_t\n",
        "print(\"4) After manual seed(0):\")\n",
        "print(tensor_4)\n",
        "print(tensor_4_b)\n",
        "print(matmul_4)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ezY6ks9Cis37"
      },
      "source": [
        "### 5. Speaking of random seeds, we saw how to set it with `torch.manual_seed()` but is there a GPU equivalent? (hint: you'll need to look into the documentation for `torch.cuda` for this one)\n",
        "  * If there is, set the GPU random seed to `1234`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_LKWcfSTjp00"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(0)\n",
        "cpu_rand1 = torch.rand(3)\n",
        "torch.manual_seed(0)\n",
        "cpu_rand2 = torch.rand(3)\n",
        "print(\"5) Equal after same seed:\", torch.equal(cpu_rand1, cpu_rand2))\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    cuda_rand1 = torch.cuda.FloatTensor(3).uniform_()\n",
        "    torch.cuda.manual_seed_all(0)\n",
        "    cuda_rand2 = torch.cuda.FloatTensor(3).uniform_()\n",
        "    print(\"CUDA equal after same seed:\", torch.equal(cuda_rand1.cpu(), cuda_rand2.cpu()))\n",
        "else:\n",
        "    print(\"CUDA not available.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ir9qSaj6it4n"
      },
      "source": [
        "\n",
        "### 6. Create two random tensors of shape `(2, 3)` and send them both to the GPU (you'll need access to a GPU for this). Set `torch.manual_seed(1234)` when creating the tensors (this doesn't have to be the GPU random seed). The output should be something like:\n",
        "\n",
        "```\n",
        "Device: cuda\n",
        "(tensor([[0.0290, 0.4019, 0.2598],\n",
        "         [0.3666, 0.0583, 0.7006]], device='cuda:0'),\n",
        " tensor([[0.0518, 0.4681, 0.6738],\n",
        "         [0.3315, 0.7837, 0.5631]], device='cuda:0'))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "azXExiFZj5nm"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "A = torch.rand((3,2), device=device)\n",
        "B = torch.rand((2,3), device=device)\n",
        "print(\"6) device:\", device)\n",
        "print(\"A:\", A)\n",
        "print(\"B:\", B)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TlAxeiSiu1y"
      },
      "source": [
        "\n",
        "### 7. Perform a matrix multiplication on the tensors you created in 6 (again, you may have to adjust the shapes of one of the tensors).\n",
        "\n",
        "The output should look like:\n",
        "```\n",
        "(tensor([[0.3647, 0.4709],\n",
        "         [0.5184, 0.5617]], device='cuda:0'), torch.Size([2, 2]))\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAeG7ox0lHEO"
      },
      "outputs": [],
      "source": [
        "matmul_7 = A @ B\n",
        "print(\"7) matmul result:\", matmul_7)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7qfa5CSivwg"
      },
      "source": [
        "### 8. Find the maximum and minimum values of the output of 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fu8_3mZpllOd"
      },
      "outputs": [],
      "source": [
        "print(\"8) max:\", matmul_7.max().item(), \"min:\", matmul_7.min().item())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrTj5FgNiw47"
      },
      "source": [
        "### 9. Find the maximum and minimum index values of the output of 7."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCEKt4K2lsfQ"
      },
      "outputs": [],
      "source": [
        "flat_argmax = torch.argmax(matmul_7)\n",
        "flat_argmin = torch.argmin(matmul_7)\n",
        "rows, cols = matmul_7.shape\n",
        "argmax_pos = (flat_argmax // cols, flat_argmax % cols)\n",
        "argmin_pos = (flat_argmin // cols, flat_argmin % cols)\n",
        "print(\"9) argmax:\", argmax_pos, \"argmin:\", argmin_pos)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmeybz4uixy7"
      },
      "source": [
        "\n",
        "### 10. Make a random tensor with shape `(1, 1, 1, 10)` and then create a new tensor with all the `1` dimensions removed to be left with a tensor of shape `(10)`. Set the seed to `7` when you create it and print out the first tensor and it's shape as well as the second tensor and it's shape.\n",
        "\n",
        "The output should look like:\n",
        "\n",
        "```\n",
        "tensor([[[[0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297,\n",
        "           0.3653, 0.8513]]]]) torch.Size([1, 1, 1, 10])\n",
        "tensor([0.5349, 0.1988, 0.6592, 0.6569, 0.2328, 0.4251, 0.2071, 0.6297, 0.3653,\n",
        "        0.8513]) torch.Size([10])\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TQ9zbRzVl1jV"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(42)\n",
        "t10 = torch.rand((1,1,1,10))\n",
        "t10_transposed = t10.permute(0,1,3,2)\n",
        "t10_squeezed = t10_transposed.squeeze()\n",
        "print(\"10) t10 shapes:\", t10.shape, \"->\", t10_transposed.shape, \"->\", t10_squeezed.shape)\n",
        "print(\"t10_squeezed:\",Â t10_squeezed)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "00_pytorch_fundamentals_exercises.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
